{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv('../input/train.csv')\nprint(X_train.shape)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ny_train = X_train['label']\nprint(y_train.shape)\nsns.countplot(y_train, palette='icefire')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(labels='label', axis=1)\nprint(X_train.shape)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_num = np.random.randint(1000)\nexample = X_train.iloc[select_num].values.reshape(28, 28)\nplt.imshow(example)\nplt.title(\"label: {}\".format(y_train.iloc[select_num]), fontsize=23)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_np = X_train.values / 255 #Normalization\ny_train_np = y_train.values\nX_train, X_test, y_train, y_test = train_test_split(X_train_np, y_train_np, test_size=0.2, random_state=28)\n#Create tensor for data set.\nX_Train = torch.from_numpy(X_train).type(torch.double)\ny_Train = torch.from_numpy(y_train).type(torch.LongTensor)\nX_Test = torch.from_numpy(X_test).type(torch.double)\ny_Test = torch.from_numpy(y_test).type(torch.LongTensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The shape of X_Train: {}'.format(X_Train.shape))\nprint('The shape of y_Train: {}'.format(y_Train.shape))\nprint('The shape of X_Test: {}'.format(X_Test.shape))\nprint('The shape of y_Test: {}'.format(y_Test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        #convolution layer1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        #1 * 28 * 28 -> 16 * 24 * 24\n        \n        #max pooling 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        #16 * 24 * 24 -> 16 * 12 * 12\n        \n        #convolution layer2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        #16 * 12 * 12 -> 32 * 8 * 8\n        \n        #max pooling 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        #32 * 8 * 8 -> 32 * 4 * 4\n        \n        #full connected layer 1\n        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n    \n    def forward(self, x):\n        #convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        #max pooling 1\n        out = self.maxpool1(out)\n        \n        #convolution 2\n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        #max pooling 2\n        out = self.maxpool2(out)\n        #flatten\n        out = out.view(out.size(0), -1)\n        \n        #full connected layer\n        out = self.fc1(out)\n        return out\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nn_iters = 3000\nnum_epochs = n_iters / (len(X_train) / batch_size)\nnum_epochs = int(num_epochs)\n#Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(X_Train, y_Train)\ntest = torch.utils.data.TensorDataset(X_Test, y_Test)\n#data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle=False)\n\nmodel = CNNModel()\n\nerror = nn.CrossEntropyLoss()\n\n#SGD Optimizer\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model training\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100, 1, 28, 28))\n        labels = Variable(labels)\n        #Clear gradients\n        optimizer.zero_grad()\n        \n        \n        #Forward propagation\n        model = model.double()\n        outputs = model(train.double())\n        \n        #Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n        \n        #Calculating gradients\n        loss.backward()\n        \n        #Update parameters\n        optimizer.step()\n        \n        count += 1\n        if count % 50 == 0:\n            #calculate accuracy\n            correct = 0\n            total = 0\n            for images, labels in test_loader:\n                test = Variable(images.view(100, 1, 28, 28))\n                #forward propagation\n                outputs = model(test)\n                #get prediction from the model\n                prediction = torch.max(outputs.data, 1)[1]\n                \n                total += len(labels)\n                \n                correct += (prediction == labels).sum()\n                \n            accuracy = 100 * float(correct) / float(total)\n            loss_list.append(loss.data)\n            accuracy_list.append(accuracy)\n            iteration_list.append(count)\n            if count % 500 == 0:\n                print('Iteration: {}%, loss: {}, accuracy: {}'.format(count, loss.data.item(), accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(iteration_list, accuracy_list)\nplt.xlabel('Number of iteration')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(iteration_list, loss_list)\nplt.xlabel('Number of iteration')\nplt.ylabel('Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/test.csv')\n\nprint(test_set.shape)\ntest_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/test.csv')\ntest_set.head()\ntest_set_X = test_set.values / 255\ntest_set_X_tensor = torch.from_numpy(test_set_X)\n\ntest = torch.utils.data.TensorDataset(test_set_X_tensor)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\npred_np = np.array([])\nfor images in test_loader:\n    images = images[0]\n    test_images = Variable(images.view(100, 1, 28, 28))\n    outputs = model(test_images)\n    #get prediction from the model\n    prediction = torch.max(outputs.data, 1)[1]\n    pred_np = np.hstack((pred_np, np.copy(prediction.numpy())))\npred_np.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pd.DataFrame({\"ImageId\": np.arange(1, 28001), \"Label\": pred_np}, dtype=int)\nprediction.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}